}
#load data
load("analysis/abc/abc_rf_tuning.RData")
load("analysis/main_simulations/main_simulations_1.RData")
a <- main_simulations
load("analysis/main_simulations/main_simulations_2.RData")
b <- main_simulations
load("analysis/main_simulations/main_simulations_3.RData")
c <- main_simulations
load("analysis/main_simulations/main_simulations_4.RData")
d <- main_simulations
load("analysis/main_simulations/main_simulations_5.RData")
e <- main_simulations
main_simulations <- list(priors = rbind(a$priors, b$priors, c$priors, d$priors, e$priors), sum_stats = c(a$sum_stats, b$sum_stats, c$sum_stats, d$sum_stats, e$sum_stats))
rm(list = c("a", "b", "c", "d", "e"))
#mix locations and years for 2008-2016
to_mix <- brands[which(brands[, 10] != 1990), ]
to_mix[, 9] <- sample(to_mix[, 9], length(to_mix[, 9]))
to_mix[, 10] <- sample(to_mix[, 10], length(to_mix[, 10]))
to_mix <- to_mix[order(to_mix[, 10]), ]
#separate brands data by year
brands_1990 <- data.table::data.table(brands[which(brands[, 10] == 1990), 1:9])
brands_2008 <- data.table::data.table(to_mix[which(to_mix[, 10] == 2008), 1:9])
brands_2014 <- data.table::data.table(to_mix[which(to_mix[, 10] == 2014), 1:9])
brands_2015 <- data.table::data.table(to_mix[which(to_mix[, 10] == 2015), 1:9])
brands_2016 <- data.table::data.table(to_mix[which(to_mix[, 10] == 2016), 1:9])
#get vector of observed summary statistics
obs_stats <- c(get_sum_stats(as.matrix(brands_2008), components, all_zips, angles = FALSE),
get_sum_stats(as.matrix(brands_2014), components, all_zips, angles = FALSE),
get_sum_stats(as.matrix(brands_2015), components, all_zips, angles = FALSE),
get_sum_stats(as.matrix(brands_2016), components, all_zips, angles = FALSE))
#convert to data frame with same structure as vector of observed summary statistics
sum_stats <- do.call("rbind", lapply(1:length(main_simulations$sum_stats), function(x){c(t(as.matrix(main_simulations$sum_stats[[x]])))}))
#restructure obs stats
obs_stats <- as.data.frame(t(obs_stats))
#store priors in new object for transformation for random forest
transf_priors <- main_simulations$priors
#log transform complexity and strength params, and logit transform radii (functions adopted from abc package)
logit_bounds <- c(0, 690)
logit <- function(param, logit_bounds){
temp <- (param - logit_bounds[1])/(logit_bounds[2] - logit_bounds[1])
return(log(temp/(1 - temp)))
}
inv_logit <- function(param, logit_bounds){
temp <- exp(param)/(1 + exp(param))
return((temp*(logit_bounds[2] - logit_bounds[1])) + logit_bounds[1])
}
transf_priors[, 1] <- log(transf_priors[, 1])
transf_priors[, 2] <- logit(transf_priors[, 2], logit_bounds)
transf_priors[, 3] <- logit(transf_priors[, 3], logit_bounds)
transf_priors[, 4] <- log(transf_priors[, 4])
transf_priors[, 5] <- log(transf_priors[, 5])
#set sample size for random forest (80% of data)
sample_size <- 0.8*nrow(sum_stats)
#construct object to hold predictions
abc_rf_mixed_predictions <- list()
#set number of cores
ncores <- detectCores() - 1
#set value of i
i <- 1
#set random seed
set.seed(i)
#construct data frame for random forest abc
abcrf_data <- data.frame(transf_priors[, i], sum_stats = sum_stats)
colnames(abcrf_data)[1] <- "param"
colnames(obs_stats) <- colnames(abcrf_data)[-1]
#run random forest with recommended values
reg_abcrf <- regAbcrf(formula = param ~ ., data = abcrf_data, ntree = 1000, mtry = abc_rf_tuning[[i]]$mtry, min.node.size = abc_rf_tuning[[i]]$min.node.size, sampsize = sample_size, paral = TRUE, ncores = ncores)
#add all output to the predictions object
abc_rf_mixed_predictions[[i]] <- list(OOB_MSE = reg_abcrf$model.rf$prediction.error, OOB_NMAE = reg_abcrf$model.rf$NMAE, prediction = predict(object = reg_abcrf, obs = obs_stats, training = abcrf_data, paral = TRUE, ncores = ncores),
var_importance = sort(reg_abcrf$model.rf$variable.importance, decreasing = TRUE), weights = extract_weights(object = reg_abcrf, obs = obs_stats, training = abcrf_data, paral = TRUE, ncores = ncores))
#save predictions
save(abc_rf_mixed_predictions, file = "analysis/abc/abc_rf_mixed_predictions.RData")
#add 1 to i
i <- i + 1
#set random seed
set.seed(i)
#construct data frame for random forest abc
abcrf_data <- data.frame(transf_priors[, i], sum_stats = sum_stats)
colnames(abcrf_data)[1] <- "param"
colnames(obs_stats) <- colnames(abcrf_data)[-1]
#run random forest with recommended values
reg_abcrf <- regAbcrf(formula = param ~ ., data = abcrf_data, ntree = 1000, mtry = abc_rf_tuning[[i]]$mtry, min.node.size = abc_rf_tuning[[i]]$min.node.size, sampsize = sample_size, paral = TRUE, ncores = ncores)
#add all output to the predictions object
abc_rf_mixed_predictions[[i]] <- list(OOB_MSE = reg_abcrf$model.rf$prediction.error, OOB_NMAE = reg_abcrf$model.rf$NMAE, prediction = predict(object = reg_abcrf, obs = obs_stats, training = abcrf_data, paral = TRUE, ncores = ncores),
var_importance = sort(reg_abcrf$model.rf$variable.importance, decreasing = TRUE), weights = extract_weights(object = reg_abcrf, obs = obs_stats, training = abcrf_data, paral = TRUE, ncores = ncores))
#save predictions
save(abc_rf_mixed_predictions, file = "analysis/abc/abc_rf_mixed_predictions.RData")
#add 1 to i
i <- i + 1
#set random seed
set.seed(i)
#construct data frame for random forest abc
abcrf_data <- data.frame(transf_priors[, i], sum_stats = sum_stats)
colnames(abcrf_data)[1] <- "param"
colnames(obs_stats) <- colnames(abcrf_data)[-1]
#run random forest with recommended values
reg_abcrf <- regAbcrf(formula = param ~ ., data = abcrf_data, ntree = 1000, mtry = abc_rf_tuning[[i]]$mtry, min.node.size = abc_rf_tuning[[i]]$min.node.size, sampsize = sample_size, paral = TRUE, ncores = ncores)
#add all output to the predictions object
abc_rf_mixed_predictions[[i]] <- list(OOB_MSE = reg_abcrf$model.rf$prediction.error, OOB_NMAE = reg_abcrf$model.rf$NMAE, prediction = predict(object = reg_abcrf, obs = obs_stats, training = abcrf_data, paral = TRUE, ncores = ncores),
var_importance = sort(reg_abcrf$model.rf$variable.importance, decreasing = TRUE), weights = extract_weights(object = reg_abcrf, obs = obs_stats, training = abcrf_data, paral = TRUE, ncores = ncores))
#save predictions
save(abc_rf_mixed_predictions, file = "analysis/abc/abc_rf_mixed_predictions.RData")
#add 1 to i
i <- i + 1
#set random seed
set.seed(i)
#construct data frame for random forest abc
abcrf_data <- data.frame(transf_priors[, i], sum_stats = sum_stats)
colnames(abcrf_data)[1] <- "param"
colnames(obs_stats) <- colnames(abcrf_data)[-1]
#run random forest with recommended values
reg_abcrf <- regAbcrf(formula = param ~ ., data = abcrf_data, ntree = 1000, mtry = abc_rf_tuning[[i]]$mtry, min.node.size = abc_rf_tuning[[i]]$min.node.size, sampsize = sample_size, paral = TRUE, ncores = ncores)
#add all output to the predictions object
abc_rf_mixed_predictions[[i]] <- list(OOB_MSE = reg_abcrf$model.rf$prediction.error, OOB_NMAE = reg_abcrf$model.rf$NMAE, prediction = predict(object = reg_abcrf, obs = obs_stats, training = abcrf_data, paral = TRUE, ncores = ncores),
var_importance = sort(reg_abcrf$model.rf$variable.importance, decreasing = TRUE), weights = extract_weights(object = reg_abcrf, obs = obs_stats, training = abcrf_data, paral = TRUE, ncores = ncores))
#save predictions
save(abc_rf_mixed_predictions, file = "analysis/abc/abc_rf_mixed_predictions.RData")
#add 1 to i
i <- i + 1
#set random seed
set.seed(i)
#construct data frame for random forest abc
abcrf_data <- data.frame(transf_priors[, i], sum_stats = sum_stats)
colnames(abcrf_data)[1] <- "param"
colnames(obs_stats) <- colnames(abcrf_data)[-1]
#run random forest with recommended values
reg_abcrf <- regAbcrf(formula = param ~ ., data = abcrf_data, ntree = 1000, mtry = abc_rf_tuning[[i]]$mtry, min.node.size = abc_rf_tuning[[i]]$min.node.size, sampsize = sample_size, paral = TRUE, ncores = ncores)
#add all output to the predictions object
abc_rf_mixed_predictions[[i]] <- list(OOB_MSE = reg_abcrf$model.rf$prediction.error, OOB_NMAE = reg_abcrf$model.rf$NMAE, prediction = predict(object = reg_abcrf, obs = obs_stats, training = abcrf_data, paral = TRUE, ncores = ncores),
var_importance = sort(reg_abcrf$model.rf$variable.importance, decreasing = TRUE), weights = extract_weights(object = reg_abcrf, obs = obs_stats, training = abcrf_data, paral = TRUE, ncores = ncores))
#save predictions
save(abc_rf_mixed_predictions, file = "analysis/abc/abc_rf_mixed_predictions.RData")
#add 1 to i
i <- i + 1
#plot
xlabs <- list(expression(Complexity~"("*italic(paste(lambda))*")"), expression(Copy~Radius~"("*italic(R[C])*")"), expression(Dist~Radius~"("*italic(R[D])*")"), expression(Copy~Strength~"("*italic(C)*")"), expression(Dist~Strength~"("*italic(D)*")"))
xlims <- list(c(0, 8), c(1, 689), c(1, 689), c(0, 10), c(0, 10))
group_lines <- c("0" = "dotted", "1" = "solid", "2" = "solid")
group_colors <- c("0" = "black", "1" = "black", "2" = "red")
for(i in 1:ncol(transf_priors)){
if(i %in% c(1, 4, 5)){
temp <- density(exp(transf_priors[, i]), weights = abc_rf_predictions[[i]]$weights)
temp_mixed <- density(exp(transf_priors[, i]), weights = abc_rf_mixed_predictions[[i]]$weights)
prior <- data.frame(value = density(exp(transf_priors[, i]))$x, density = density(exp(transf_priors[, i]))$y, id = 0, lt = 0, color = 0)
} else{
temp <- density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds), weights = abc_rf_predictions[[i]]$weights)
temp_mixed <- density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds), weights = abc_rf_mixed_predictions[[i]]$weights)
prior <- data.frame(value = density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds))$x, density = density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds))$y, id = 0, lt = 0, color = 0)
}
posterior <- data.frame(value = temp$x, density = temp$y, id = 1, lt = 1, color = 1)
posterior_mixed <- data.frame(value = temp_mixed$x, density = temp_mixed$y, id = 2, lt = 2, color = 2)
combined <- rbind(posterior, posterior_mixed, prior)
plot <- ggplot(combined) + geom_line(mapping = aes(x = value, y = density, group = id, linetype = as.factor(lt), color = as.factor(color))) +
labs(x = xlabs[[i]], y = "Density") + xlim(xlims[[i]]) +
theme_linedraw() + scale_color_manual(guide = "none", name = NULL, values = group_colors) +
scale_linetype_manual(name = NULL, values = group_lines, labels = c("Prior", "Posterior", "Mixed"), guide = guide_legend(override.aes = list(color = group_colors)))
assign(names(transf_priors)[i], plot)
}
#load saved predictions
load("analysis/abc/abc_rf_predictions.RData")
xlabs <- list(expression(Complexity~"("*italic(paste(lambda))*")"), expression(Copy~Radius~"("*italic(R[C])*")"), expression(Dist~Radius~"("*italic(R[D])*")"), expression(Copy~Strength~"("*italic(C)*")"), expression(Dist~Strength~"("*italic(D)*")"))
xlims <- list(c(0, 8), c(1, 689), c(1, 689), c(0, 10), c(0, 10))
group_lines <- c("0" = "dotted", "1" = "solid", "2" = "solid")
group_colors <- c("0" = "black", "1" = "black", "2" = "red")
for(i in 1:ncol(transf_priors)){
if(i %in% c(1, 4, 5)){
temp <- density(exp(transf_priors[, i]), weights = abc_rf_predictions[[i]]$weights)
temp_mixed <- density(exp(transf_priors[, i]), weights = abc_rf_mixed_predictions[[i]]$weights)
prior <- data.frame(value = density(exp(transf_priors[, i]))$x, density = density(exp(transf_priors[, i]))$y, id = 0, lt = 0, color = 0)
} else{
temp <- density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds), weights = abc_rf_predictions[[i]]$weights)
temp_mixed <- density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds), weights = abc_rf_mixed_predictions[[i]]$weights)
prior <- data.frame(value = density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds))$x, density = density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds))$y, id = 0, lt = 0, color = 0)
}
posterior <- data.frame(value = temp$x, density = temp$y, id = 1, lt = 1, color = 1)
posterior_mixed <- data.frame(value = temp_mixed$x, density = temp_mixed$y, id = 2, lt = 2, color = 2)
combined <- rbind(posterior, posterior_mixed, prior)
plot <- ggplot(combined) + geom_line(mapping = aes(x = value, y = density, group = id, linetype = as.factor(lt), color = as.factor(color))) +
labs(x = xlabs[[i]], y = "Density") + xlim(xlims[[i]]) +
theme_linedraw() + scale_color_manual(guide = "none", name = NULL, values = group_colors) +
scale_linetype_manual(name = NULL, values = group_lines, labels = c("Prior", "Posterior", "Mixed"), guide = guide_legend(override.aes = list(color = group_colors)))
assign(names(transf_priors)[i], plot)
}
#com
legend <- get_legend(complexity)
plot_grid(complexity + theme(legend.position="none"),
copy_radius + theme(legend.position="none"),
dist_radius + theme(legend.position="none"),
copy_strength + theme(legend.position="none"),
dist_strength + theme(legend.position="none"),
legend, labels = c("A", "B", "C", "D", "E"), align = "hv")
xlabs <- list(expression(Complexity~"("*italic(paste(lambda))*")"), expression(Copy~Radius~"("*italic(R[C])*")"), expression(Dist~Radius~"("*italic(R[D])*")"), expression(Copy~Strength~"("*italic(C)*")"), expression(Dist~Strength~"("*italic(D)*")"))
xlims <- list(c(0, 8), c(1, 689), c(1, 689), c(0, 10), c(0, 10))
group_lines <- c("0" = "dotted", "1" = "solid", "2" = "solid")
group_colors <- c("0" = "black", "1" = "black", "2" = "#0072B2")
for(i in 1:ncol(transf_priors)){
if(i %in% c(1, 4, 5)){
temp <- density(exp(transf_priors[, i]), weights = abc_rf_predictions[[i]]$weights)
temp_mixed <- density(exp(transf_priors[, i]), weights = abc_rf_mixed_predictions[[i]]$weights)
prior <- data.frame(value = density(exp(transf_priors[, i]))$x, density = density(exp(transf_priors[, i]))$y, id = 0, lt = 0, color = 0)
} else{
temp <- density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds), weights = abc_rf_predictions[[i]]$weights)
temp_mixed <- density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds), weights = abc_rf_mixed_predictions[[i]]$weights)
prior <- data.frame(value = density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds))$x, density = density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds))$y, id = 0, lt = 0, color = 0)
}
posterior <- data.frame(value = temp$x, density = temp$y, id = 1, lt = 1, color = 1)
posterior_mixed <- data.frame(value = temp_mixed$x, density = temp_mixed$y, id = 2, lt = 2, color = 2)
combined <- rbind(posterior, posterior_mixed, prior)
plot <- ggplot(combined) + geom_line(mapping = aes(x = value, y = density, group = id, linetype = as.factor(lt), color = as.factor(color))) +
labs(x = xlabs[[i]], y = "Density") + xlim(xlims[[i]]) +
theme_linedraw() + scale_color_manual(guide = "none", name = NULL, values = group_colors) +
scale_linetype_manual(name = NULL, values = group_lines, labels = c("Prior", "Posterior", "Mixed"), guide = guide_legend(override.aes = list(color = group_colors)))
assign(names(transf_priors)[i], plot)
}
legend <- get_legend(complexity)
plot_grid(complexity + theme(legend.position="none"),
copy_radius + theme(legend.position="none"),
dist_radius + theme(legend.position="none"),
copy_strength + theme(legend.position="none"),
dist_strength + theme(legend.position="none"),
legend, labels = c("A", "B", "C", "D", "E"), align = "hv")
xlabs <- list(expression(Complexity~"("*italic(paste(lambda))*")"), expression(Copy~Radius~"("*italic(R[C])*")"), expression(Dist~Radius~"("*italic(R[D])*")"), expression(Copy~Strength~"("*italic(C)*")"), expression(Dist~Strength~"("*italic(D)*")"))
xlims <- list(c(0, 8), c(1, 689), c(1, 689), c(0, 10), c(0, 10))
group_lines <- c("0" = "dotted", "1" = "solid", "2" = "solid")
group_colors <- c("0" = "black", "1" = "black", "2" = "#D55E00")
for(i in 1:ncol(transf_priors)){
if(i %in% c(1, 4, 5)){
temp <- density(exp(transf_priors[, i]), weights = abc_rf_predictions[[i]]$weights)
temp_mixed <- density(exp(transf_priors[, i]), weights = abc_rf_mixed_predictions[[i]]$weights)
prior <- data.frame(value = density(exp(transf_priors[, i]))$x, density = density(exp(transf_priors[, i]))$y, id = 0, lt = 0, color = 0)
} else{
temp <- density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds), weights = abc_rf_predictions[[i]]$weights)
temp_mixed <- density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds), weights = abc_rf_mixed_predictions[[i]]$weights)
prior <- data.frame(value = density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds))$x, density = density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds))$y, id = 0, lt = 0, color = 0)
}
posterior <- data.frame(value = temp$x, density = temp$y, id = 1, lt = 1, color = 1)
posterior_mixed <- data.frame(value = temp_mixed$x, density = temp_mixed$y, id = 2, lt = 2, color = 2)
combined <- rbind(posterior, posterior_mixed, prior)
plot <- ggplot(combined) + geom_line(mapping = aes(x = value, y = density, group = id, linetype = as.factor(lt), color = as.factor(color))) +
labs(x = xlabs[[i]], y = "Density") + xlim(xlims[[i]]) +
theme_linedraw() + scale_color_manual(guide = "none", name = NULL, values = group_colors) +
scale_linetype_manual(name = NULL, values = group_lines, labels = c("Prior", "Posterior", "Mixed"), guide = guide_legend(override.aes = list(color = group_colors)))
assign(names(transf_priors)[i], plot)
}
legend <- get_legend(complexity)
plot_grid(complexity + theme(legend.position="none"),
copy_radius + theme(legend.position="none"),
dist_radius + theme(legend.position="none"),
copy_strength + theme(legend.position="none"),
dist_strength + theme(legend.position="none"),
legend, labels = c("A", "B", "C", "D", "E"), align = "hv")
xlabs <- list(expression(Complexity~"("*italic(paste(lambda))*")"), expression(Copy~Radius~"("*italic(R[C])*")"), expression(Dist~Radius~"("*italic(R[D])*")"), expression(Copy~Strength~"("*italic(C)*")"), expression(Dist~Strength~"("*italic(D)*")"))
xlims <- list(c(0, 8), c(1, 689), c(1, 689), c(0, 10), c(0, 10))
group_lines <- c("0" = "dotted", "1" = "solid", "2" = "solid")
group_colors <- c("0" = "black", "1" = "#0072B2", "2" = "#D55E00")
for(i in 1:ncol(transf_priors)){
if(i %in% c(1, 4, 5)){
temp <- density(exp(transf_priors[, i]), weights = abc_rf_predictions[[i]]$weights)
temp_mixed <- density(exp(transf_priors[, i]), weights = abc_rf_mixed_predictions[[i]]$weights)
prior <- data.frame(value = density(exp(transf_priors[, i]))$x, density = density(exp(transf_priors[, i]))$y, id = 0, lt = 0, color = 0)
} else{
temp <- density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds), weights = abc_rf_predictions[[i]]$weights)
temp_mixed <- density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds), weights = abc_rf_mixed_predictions[[i]]$weights)
prior <- data.frame(value = density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds))$x, density = density(inv_logit(transf_priors[, i], logit_bounds = logit_bounds))$y, id = 0, lt = 0, color = 0)
}
posterior <- data.frame(value = temp$x, density = temp$y, id = 1, lt = 1, color = 1)
posterior_mixed <- data.frame(value = temp_mixed$x, density = temp_mixed$y, id = 2, lt = 2, color = 2)
combined <- rbind(posterior, posterior_mixed, prior)
plot <- ggplot(combined) + geom_line(mapping = aes(x = value, y = density, group = id, linetype = as.factor(lt), color = as.factor(color))) +
labs(x = xlabs[[i]], y = "Density") + xlim(xlims[[i]]) +
theme_linedraw() + scale_color_manual(guide = "none", name = NULL, values = group_colors) +
scale_linetype_manual(name = NULL, values = group_lines, labels = c("Prior", "Posterior", "Mixed"), guide = guide_legend(override.aes = list(color = group_colors)))
assign(names(transf_priors)[i], plot)
}
legend <- get_legend(complexity)
plot_grid(complexity + theme(legend.position="none"),
copy_radius + theme(legend.position="none"),
dist_radius + theme(legend.position="none"),
copy_strength + theme(legend.position="none"),
dist_strength + theme(legend.position="none"),
legend, labels = c("A", "B", "C", "D", "E"), align = "hv")
png("analysis/abc/abc_rf_mixed_posteriors.png", units = "in", width = 11, height = 7, res = 300)
legend <- get_legend(complexity)
plot_grid(complexity + theme(legend.position="none"),
copy_radius + theme(legend.position="none"),
dist_radius + theme(legend.position="none"),
copy_strength + theme(legend.position="none"),
dist_strength + theme(legend.position="none"),
legend, labels = c("A", "B", "C", "D", "E"), align = "hv")
dev.off()
?tiff
#set workspace
setwd("~/Documents/Work/Spring 2022/Police Budgets/police_budget_analysis_2018_2022")
#load packages
library(reshape2)
library(fitdistrplus)
library(brms)
library(ggplot2)
library(performance)
library(cowplot)
#load data
data <- readxl::read_xlsx("police_budgets_2018_2022.xlsx")
#subset and clean data
data <- data[-which(is.na(data$p18) | is.na(data$gf18) | is.na(data$p19) | is.na(data$gf19) | is.na(data$p20) | is.na(data$gf20) | is.na(data$p21) | is.na(data$gf21) | is.na(data$p22) | is.na(data$gf22)), ]
data <- data[, which(colnames(data) %in% c("state", "city", "p18", "gf18", "p19", "gf19", "p20", "gf20", "p21", "gf21", "p22", "gf22"))]
colnames(data) <- c("state", "city", "p18", "g18", "p19", "g19", "p20", "g20", "p21", "g21", "p22", "g22")
#create summary data frames
summary_data_a <- data.frame(Year = c(rep("2018", 2), rep("2019", 2), rep("2020", 2), rep("2021", 2), rep("2022", 2)),
Category = rep(c("Police", "General"), 5),
values = c(mean(data$p18), mean(data$g18)-mean(data$p18),
mean(data$p19), mean(data$g19)-mean(data$p19),
mean(data$p20), mean(data$g20)-mean(data$p20),
mean(data$p21), mean(data$g21)-mean(data$p21),
mean(data$p22), mean(data$g22)-mean(data$p22)))
summary_data_b <- data.frame(Year = c("2018", "2019", "2020", "2021", "2022"),
avg_percent = c(mean(data$p18/data$g18), mean(data$p19/data$g19), mean(data$p20/data$g20),
mean(data$p21/data$g21), mean(data$p22/data$g22)))
#plot stacked bar graph
bar_plot_a <- ggplot(summary_data_a, aes(fill = Category, y = values, x = Year)) + geom_bar(position = "stack", stat = "identity") +
theme_linedraw() +
scale_y_continuous(breaks = c(0, 50000000, 100000000, 150000000, 200000000, 250000000), labels = c("$0", "$50M", "$100M", "$150M", "$200M", "$250M")) + ylab("Average Budget")
#plot basic bar graph
bar_plot_b <- ggplot(summary_data_b, aes(y = avg_percent, x = Year)) + geom_bar(stat = "identity", fill = "#00BFC4") +
theme_linedraw() + theme(legend.position = "none") + scale_y_continuous(labels = scales::percent_format()) + ylab("Percent on Police")
#save bar combined bar graph
tiff("bar_plot_combined.tiff", width = 9, height = 4, units = "in" , res = 300)
plot_grid(bar_plot_a, bar_plot_b, rel_widths = c(1.28, 1), labels = c("A", "B"))
dev.off()
?pdf
pdf("bar_plot_combined.tiff", width = 9, height = 4, units = "in" , res = 300)
pdf("bar_plot_combined.tiff", width = 9, height = 4)
plot_grid(bar_plot_a, bar_plot_b, rel_widths = c(1.28, 1), labels = c("A", "B"))
dev.off()
pdf("bar_plot_combined.pdf", width = 9, height = 4)
plot_grid(bar_plot_a, bar_plot_b, rel_widths = c(1.28, 1), labels = c("A", "B"))
dev.off()
?ggsave
#create data frame for each example city and combine
minneapolis_data <- data[which(data$city == "minneapolis"),]
minneapolis_data <- data.frame(Year = c(rep("2018", 2), rep("2019", 2), rep("2020", 2), rep("2021", 2), rep("2022", 2)),
Category = rep(c("Police", "General"), 5),
values = c(mean(minneapolis_data$p18), mean(minneapolis_data$g18)-mean(minneapolis_data$p18),
mean(minneapolis_data$p19), mean(minneapolis_data$g19)-mean(minneapolis_data$p19),
mean(minneapolis_data$p20), mean(minneapolis_data$g20)-mean(minneapolis_data$p20),
mean(minneapolis_data$p21), mean(minneapolis_data$g21)-mean(minneapolis_data$p21),
mean(minneapolis_data$p22), mean(minneapolis_data$g22)-mean(minneapolis_data$p22)),
City = rep("Minneapolis", 10))
seattle_data <- data[which(data$city == "seattle"),]
seattle_data <- data.frame(Year = c(rep("2018", 2), rep("2019", 2), rep("2020", 2), rep("2021", 2), rep("2022", 2)),
Category = rep(c("Police", "General"), 5),
values = c(mean(seattle_data$p18), mean(seattle_data$g18)-mean(seattle_data$p18),
mean(seattle_data$p19), mean(seattle_data$g19)-mean(seattle_data$p19),
mean(seattle_data$p20), mean(seattle_data$g20)-mean(seattle_data$p20),
mean(seattle_data$p21), mean(seattle_data$g21)-mean(seattle_data$p21),
mean(seattle_data$p22), mean(seattle_data$g22)-mean(seattle_data$p22)),
City = rep("Seattle", 10))
austin_data <- data[which(data$city == "austin"),]
austin_data <- data.frame(Year = c(rep("2018", 2), rep("2019", 2), rep("2020", 2), rep("2021", 2), rep("2022", 2)),
Category = rep(c("Police", "General"), 5),
values = c(mean(austin_data$p18), mean(austin_data$g18)-mean(austin_data$p18),
mean(austin_data$p19), mean(austin_data$g19)-mean(austin_data$p19),
mean(austin_data$p20), mean(austin_data$g20)-mean(austin_data$p20),
mean(austin_data$p21), mean(austin_data$g21)-mean(austin_data$p21),
mean(austin_data$p22), mean(austin_data$g22)-mean(austin_data$p22)),
City = rep("Austin", 10))
cities_data <- rbind(minneapolis_data, seattle_data, austin_data)
#create plot
cities_plot <- ggplot(cities_data, aes(x = Year, y = values, fill = Category)) + geom_bar(stat = "identity", position = "stack") +
facet_grid(cols = vars(City)) + theme_linedraw() +
scale_y_continuous(breaks = c(0, 500000000, 1000000000, 1500000000), labels = c("$0", "$0.5B", "$1B", "$1.5B")) + ylab("Budget")
#save plot
ggsave("cities_plot.pdf", plot = cities_plot, width = 8, height = 4, units = "in", dpi = 300)
#set workspace
setwd("~/Documents/Work/Spring 2022/Police Budgets/police_budget_analysis_2018_2022")
#load packages
library(reshape2)
library(fitdistrplus)
library(brms)
library(ggplot2)
library(performance)
library(cowplot)
#load data
data <- readxl::read_xlsx("police_budgets_2018_2022.xlsx")
#subset and clean data
data <- data[-which(is.na(data$p18) | is.na(data$gf18) | is.na(data$p19) | is.na(data$gf19) | is.na(data$p20) | is.na(data$gf20) | is.na(data$p21) | is.na(data$gf21) | is.na(data$p22) | is.na(data$gf22)), ]
data <- data[, which(colnames(data) %in% c("state", "city", "p18", "gf18", "p19", "gf19", "p20", "gf20", "p21", "gf21", "p22", "gf22"))]
colnames(data) <- c("state", "city", "p18", "g18", "p19", "g19", "p20", "g20", "p21", "g21", "p22", "g22")
#create summary data frames
summary_data_a <- data.frame(Year = c(rep("2018", 2), rep("2019", 2), rep("2020", 2), rep("2021", 2), rep("2022", 2)),
Category = rep(c("Police", "General"), 5),
values = c(mean(data$p18), mean(data$g18)-mean(data$p18),
mean(data$p19), mean(data$g19)-mean(data$p19),
mean(data$p20), mean(data$g20)-mean(data$p20),
mean(data$p21), mean(data$g21)-mean(data$p21),
mean(data$p22), mean(data$g22)-mean(data$p22)))
summary_data_b <- data.frame(Year = c("2018", "2019", "2020", "2021", "2022"),
avg_percent = c(mean(data$p18/data$g18), mean(data$p19/data$g19), mean(data$p20/data$g20),
mean(data$p21/data$g21), mean(data$p22/data$g22)))
#plot stacked bar graph
bar_plot_a <- ggplot(summary_data_a, aes(fill = Category, y = values, x = Year)) + geom_bar(position = "stack", stat = "identity") +
theme_linedraw() +
scale_y_continuous(breaks = c(0, 50000000, 100000000, 150000000, 200000000, 250000000), labels = c("$0", "$50M", "$100M", "$150M", "$200M", "$250M")) + ylab("Average Budget")
#plot basic bar graph
bar_plot_b <- ggplot(summary_data_b, aes(y = avg_percent, x = Year)) + geom_bar(stat = "identity", fill = "#00BFC4") +
theme_linedraw() + theme(legend.position = "none") + scale_y_continuous(labels = scales::percent_format()) + ylab("Percent on Police")
#save bar combined bar graph
pdf("bar_plot_combined.pdf", width = 9, height = 4)
plot_grid(bar_plot_a, bar_plot_b, rel_widths = c(1.28, 1), labels = c("A", "B"))
dev.off()
#save and print stacked bar graph
ggsave("bar_plot.pdf", plot = bar_plot_a, width = 5, height = 4, units = "in", dpi = 300)
bar_plot_a
#create data frame for each example city and combine
minneapolis_data <- data[which(data$city == "minneapolis"),]
minneapolis_data <- data.frame(Year = c(rep("2018", 2), rep("2019", 2), rep("2020", 2), rep("2021", 2), rep("2022", 2)),
Category = rep(c("Police", "General"), 5),
values = c(mean(minneapolis_data$p18), mean(minneapolis_data$g18)-mean(minneapolis_data$p18),
mean(minneapolis_data$p19), mean(minneapolis_data$g19)-mean(minneapolis_data$p19),
mean(minneapolis_data$p20), mean(minneapolis_data$g20)-mean(minneapolis_data$p20),
mean(minneapolis_data$p21), mean(minneapolis_data$g21)-mean(minneapolis_data$p21),
mean(minneapolis_data$p22), mean(minneapolis_data$g22)-mean(minneapolis_data$p22)),
City = rep("Minneapolis", 10))
seattle_data <- data[which(data$city == "seattle"),]
seattle_data <- data.frame(Year = c(rep("2018", 2), rep("2019", 2), rep("2020", 2), rep("2021", 2), rep("2022", 2)),
Category = rep(c("Police", "General"), 5),
values = c(mean(seattle_data$p18), mean(seattle_data$g18)-mean(seattle_data$p18),
mean(seattle_data$p19), mean(seattle_data$g19)-mean(seattle_data$p19),
mean(seattle_data$p20), mean(seattle_data$g20)-mean(seattle_data$p20),
mean(seattle_data$p21), mean(seattle_data$g21)-mean(seattle_data$p21),
mean(seattle_data$p22), mean(seattle_data$g22)-mean(seattle_data$p22)),
City = rep("Seattle", 10))
austin_data <- data[which(data$city == "austin"),]
austin_data <- data.frame(Year = c(rep("2018", 2), rep("2019", 2), rep("2020", 2), rep("2021", 2), rep("2022", 2)),
Category = rep(c("Police", "General"), 5),
values = c(mean(austin_data$p18), mean(austin_data$g18)-mean(austin_data$p18),
mean(austin_data$p19), mean(austin_data$g19)-mean(austin_data$p19),
mean(austin_data$p20), mean(austin_data$g20)-mean(austin_data$p20),
mean(austin_data$p21), mean(austin_data$g21)-mean(austin_data$p21),
mean(austin_data$p22), mean(austin_data$g22)-mean(austin_data$p22)),
City = rep("Austin", 10))
cities_data <- rbind(minneapolis_data, seattle_data, austin_data)
#create plot
cities_plot <- ggplot(cities_data, aes(x = Year, y = values, fill = Category)) + geom_bar(stat = "identity", position = "stack") +
facet_grid(cols = vars(City)) + theme_linedraw() +
scale_y_continuous(breaks = c(0, 500000000, 1000000000, 1500000000), labels = c("$0", "$0.5B", "$1B", "$1.5B")) + ylab("Budget")
#save plot
ggsave("cities_plot.pdf", plot = cities_plot, width = 8, height = 4, units = "in", dpi = 300)
#temporary data frame with 2019 data
temp_data <- data.frame(prop = data$p19/data$g19, overall = data$g19)
#plot
ggplot(temp_data, aes(x = overall, y = prop)) + geom_point() + scale_x_continuous(trans = "log2", labels = scales::label_number_si(accuracy = 0.1, prefix = "$")) + theme_linedraw() +
geom_smooth(method = lm , color = "black", fill = "grey", se = TRUE) + xlab("Total General Fund (Log-Transformed)") + ylab("Proportion on Police")
rm(temp_data)
#convert cities and states to lower case
data$city <- as.factor(tolower(data$city))
data$state <- as.factor(tolower(data$state))
#restructure to be proportion spent on police
data_p <- data.frame(city = data$city, state = data$state, "2018" = data$p18/data$g18, "2019" = data$p19/data$g19, "2020" = data$p20/data$g20, "2021" = data$p21/data$g21, "2022" = data$p22/data$g22)
#convert police data to long format
data_p <- melt(data_p, id.vars = c("city", "state"))
colnames(data_p) <- c("city", "state", "year", "police")
data_p$year <- as.numeric(substr(data_p$year, 2, 5))
#do the same for general fund data and combine
data_g <- data.frame(city = data$city, state = data$state, "2018" = data$g18, "2019" = data$g19, "2020" = data$g20, "2021" = data$g21, "2022" = data$g22)
data_g <- melt(data_g, id.vars = c("city", "state"))
colnames(data_g) <- c("city", "state", "year", "general")
data_g$year <- as.numeric(substr(data_g$year, 2, 5))
#overwrite original data object
data <- cbind(data_p, general = data_g$general)
#violin plot
violin_plot <- ggplot(data, aes(x = as.factor(year), y = police, fill = as.factor(year))) + geom_violin() +
theme_linedraw() + theme(legend.position = "none") +
scale_y_continuous(labels = scales::percent_format()) + ylab("Percent on Police") +
scale_x_discrete(labels = c("2018", "2019", "2020", "2021", "2022")) + xlab("Year")
#save plots
ggsave("violin_plot.pdf", plot = violin_plot, width = 4, height = 4, units = "in", dpi = 300)
pdf("bar_violin_combined.pdf", width = 9, height = 4)
plot_grid(bar_plot_a, violin_plot, rel_widths = c(1.28, 1), labels = c("A", "B"))
dev.off()
#jitter plot
jitter_plot <- ggplot(data, aes(x = as.factor(year), y = police, color = as.factor(year))) + geom_jitter(position = position_jitter(0.2)) +
theme_linedraw() + theme(legend.position = "none") +
scale_y_continuous(labels = scales::percent_format()) + ylab("Percent on Police") +
scale_x_discrete(labels = c("2018", "2019", "2020", "2021", "2022")) + xlab("Year") +
stat_summary(fun = mean, geom = "point", size = 3, color = "black")
#box plot
box_plot <- ggplot(data, aes(x = as.factor(year), y = police, fill = as.factor(year))) + geom_boxplot() +
theme_linedraw() + theme(legend.position = "none") +
scale_y_continuous(labels = scales::percent_format()) + ylab("Percent on Police") +
scale_x_discrete(labels = c("2018", "2019", "2020", "2021", "2022")) + xlab("Year")
#pct change violin plot
data_2018 <- data[which(data$year == 2018), ]
data_2019 <- data[which(data$year == 2019), ]
data_2020 <- data[which(data$year == 2020), ]
data_2021 <- data[which(data$year == 2021), ]
data_2022 <- data[which(data$year == 2022), ]
data_pct_change <- data.frame(city = c(rep(data_2018$city, 4)),
year = c(rep("2018-2019", nrow(data_2018)), rep("2019-2020", nrow(data_2018)),
rep("2020-2021", nrow(data_2018)), rep("2021-2022", nrow(data_2018))),
pct_change = c(data_2019$police-data_2018$police,
data_2020$police-data_2019$police,
data_2021$police-data_2020$police,
data_2022$police-data_2021$police))
pct_change_violin_plot <- ggplot(data_pct_change, aes(x = as.factor(year), y = pct_change, fill = as.factor(year))) + geom_violin() +
theme_linedraw() + theme(legend.position = "none") +
scale_y_continuous(labels = scales::percent_format()) + ylab("Percent Change on Police") + xlab("Compared Years")
rm(list = c("data_2018", "data_2019", "data_2020", "data_2021", "data_2022", "data_pct_change"))
#save plots
ggsave("jitter_plot.pdf", plot = jitter_plot, width = 4, height = 4, units = "in", dpi = 300)
ggsave("box_plot.pdf", plot = box_plot, width = 4, height = 4, units = "in", dpi = 300)
ggsave("pct_change_violin_plot.pdf", plot = pct_change_violin_plot, width = 4, height = 4, units = "in", dpi = 300)
